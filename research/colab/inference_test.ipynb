{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b681925a",
   "metadata": {},
   "source": [
    "# ðŸ§ª Inference Test Notebook\n",
    "\n",
    "This notebook tests the fine-tuned model's ability to generate structured JSON outputs.\n",
    "\n",
    "## Purpose\n",
    "- Validate JSON output format\n",
    "- Check schema compliance\n",
    "- Measure inference latency\n",
    "- Test edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e2b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q unsloth transformers peft accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ae94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from unsloth import FastLanguageModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5579d0",
   "metadata": {},
   "source": [
    "## 1. Load Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7343ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model with LoRA adapters\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"text-to-action-lora\",  # Path to saved LoRA adapters\n",
    "    max_seq_length=2048,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "print(\"Model loaded for inference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ff8903",
   "metadata": {},
   "source": [
    "## 2. Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_action_plan(instruction: str) -> dict:\n",
    "    \"\"\"Generate structured action plan from natural language instruction.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"### Instruction:\n",
    "You are an AI that converts natural language instructions into structured JSON action plans.\n",
    "Given the following instruction, output a valid JSON with these fields:\n",
    "- object: the object to manipulate\n",
    "- initial_position: where the object currently is\n",
    "- action: what to do (move, rotate, scale)\n",
    "- target_position: the destination or target state\n",
    "\n",
    "### Input:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=128,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    latency = time.time() - start_time\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    json_str = response.split(\"### Response:\")[-1].strip()\n",
    "    \n",
    "    # Try to parse JSON\n",
    "    try:\n",
    "        result = json.loads(json_str)\n",
    "        result['_latency_ms'] = round(latency * 1000, 2)\n",
    "        result['_valid_json'] = True\n",
    "    except json.JSONDecodeError:\n",
    "        result = {\n",
    "            '_raw_output': json_str,\n",
    "            '_valid_json': False,\n",
    "            '_latency_ms': round(latency * 1000, 2)\n",
    "        }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33922f",
   "metadata": {},
   "source": [
    "## 3. Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6803d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test cases\n",
    "test_cases = [\n",
    "    \"Move the red box to the blue platform\",\n",
    "    \"Rotate the green sphere 90 degrees\",\n",
    "    \"Scale the yellow cube to twice its size\",\n",
    "    \"Place the purple cylinder on the shelf\",\n",
    "    \"Spin the orange cone 180 degrees clockwise\",\n",
    "    \"Shrink the white ball by half\",\n",
    "]\n",
    "\n",
    "print(f\"Running {len(test_cases)} test cases...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e638c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tests\n",
    "results = []\n",
    "\n",
    "for i, instruction in enumerate(test_cases, 1):\n",
    "    print(f\"Test {i}: {instruction}\")\n",
    "    result = generate_action_plan(instruction)\n",
    "    results.append(result)\n",
    "    print(f\"Result: {json.dumps(result, indent=2)}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148334ad",
   "metadata": {},
   "source": [
    "## 4. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "valid_json_count = sum(1 for r in results if r.get('_valid_json', False))\n",
    "total_count = len(results)\n",
    "avg_latency = sum(r['_latency_ms'] for r in results) / total_count\n",
    "\n",
    "# Check schema compliance\n",
    "required_fields = {'object', 'initial_position', 'action', 'target_position'}\n",
    "schema_compliant = sum(\n",
    "    1 for r in results \n",
    "    if r.get('_valid_json') and required_fields.issubset(r.keys())\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"JSON Validity Rate: {valid_json_count}/{total_count} ({100*valid_json_count/total_count:.1f}%)\")\n",
    "print(f\"Schema Compliance Rate: {schema_compliant}/{total_count} ({100*schema_compliant/total_count:.1f}%)\")\n",
    "print(f\"Average Latency: {avg_latency:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7614823",
   "metadata": {},
   "source": [
    "## 5. Edge Case Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713bbd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge cases\n",
    "edge_cases = [\n",
    "    \"Move it there\",  # Vague reference\n",
    "    \"Do something with the box\",  # Unclear action\n",
    "    \"Mov the rd bx to platfrm\",  # Typos\n",
    "    \"\",  # Empty input\n",
    "    \"Move the box, rotate it, then scale it\",  # Multiple actions\n",
    "]\n",
    "\n",
    "print(\"Testing edge cases...\\n\")\n",
    "for instruction in edge_cases:\n",
    "    print(f\"Input: '{instruction}'\")\n",
    "    result = generate_action_plan(instruction)\n",
    "    print(f\"Valid JSON: {result.get('_valid_json', False)}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a3637e",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Improve handling of edge cases** - Add training examples for ambiguous inputs\n",
    "2. **Latency optimization** - Consider model quantization or distillation\n",
    "3. **Batch inference** - Test throughput with multiple concurrent requests"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
